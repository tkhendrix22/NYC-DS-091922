{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Ensemble Learning: Gradient Boosting\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC Nov 2022\n",
    "<p>Phase 3: Topic 30</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sympy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f3b5e8a7e105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sympy'"
     ]
    }
   ],
   "source": [
    "import sympy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Boosting\n",
    "- Besides bagging: other major framework for ensemble tree learning\n",
    "- Different philosophies of learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Ralph Nader philosophy of learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images\\mistake_nader.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images\\nader.jpeg\" />\n",
    "<center> Nader giving you life lessons about learning theory AND the true source of income inequality in this country. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Boosting is essentially this:\n",
    "- at each step learner trains on mistakes of previous step.\n",
    "- uses knowledge of mistakes to correct predictions in next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**More technically**\n",
    "- Trying to approximate collection of targets $\\{y_i\\}$ with a function $F(x_i)$.\n",
    "\n",
    "Boosting: sequentially update F via step-by-step learning from errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/boosting_update.png\" width = 500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But there's a general problem with this:\n",
    "- what if what we learn from last mistake is gleaned from a set of situations that are too specific?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**More technically**\n",
    "\n",
    "Weighting last mistake with respect to the specific training data too strongly.\n",
    "\n",
    "- Our corrections to how we predict will then be too specific to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**I just overfitted**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Yes I learned from a specific set of mistakes:\n",
    "- but have I learned a sufficiently general lesson?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Want to learn from last mistakes in a way that is **generalizable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One possibility: \n",
    "- don't weight lesson from any one mistake too strongly.\n",
    "- perhaps even learn from different mistakes in a \"weak\" manner\n",
    "- BUT do this a bunch of times in sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The hope is that eventually:\n",
    "\n",
    "- Gain wisdom via each generation learning from the previous \n",
    "- But in a weak way: take some of the \"lessons\" but not all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><b> Can such a sequence of weak learners create a single strong learner? </b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The answer is yes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/boosting_update.png\" width = 500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Getting better approximations on $F$ iteratively.\n",
    "- Looks a lot like gradient descent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Use regression as example:\n",
    "\n",
    "- Least squares objective function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sympy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9ecea8889946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x, y, i, N, h_0, F\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sympy'"
     ]
    }
   ],
   "source": [
    "from sympy import *\n",
    "from sympy.abc import x, y\n",
    "\n",
    "x, y, i, N, h, F = symbols(\"x, y, i, N, h_0, F\")\n",
    "L = summation((Indexed('y',i) - F)**2 ,(i,1,N))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Take gradient with respect to the function $F$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gradL = diff(L, F)\n",
    "gradL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Thus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\nabla_FL = \\sum_{i=1}^N \\Big(F(x_i)- y_i\\Big) $$\n",
    "\n",
    "or $$ - \\nabla_FL = \\sum_{i=1}^N  \\Big(y_i - F(x_i)\\Big) $$\n",
    "**This is  error we input to learner at each step**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Input into a regressor:\n",
    "\n",
    "Want to learn from errors at given stage $m$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/train_mistakes.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we have a statistical model that can predict error from previous step:\n",
    "\n",
    "- Learned function:\n",
    "$$h_m(x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/error_prediction.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Adding this to previous estimator: previous estimator + training error\n",
    "    \n",
    "$$ F_{m+1}(x_i) = F_m(x_i) + h_m(x_i) $$\n",
    "\n",
    "Corrects for error in previous stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is good, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Not necessarily. If regressor is good at fitting error:\n",
    "\n",
    "- this is a super-strong learner:\n",
    "- Accounts too strongly for specific training errors  at step $m$.\n",
    "\n",
    "**Will introduce variance problems**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A way to make learner weak: \n",
    "- simpler decision trees\n",
    "- the learning rate $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Weaker vs. stronger learners: decision tree depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><b>Strong Learner </b> </center>\n",
    "<img src = \"Images/deep_tree.png\" />\n",
    "<center> Will train on errors at each step very well. But probably too well. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Weak learner </b></center>\n",
    "<center><img src = \"Images/dec_stump.png\" width = 250/></center>\n",
    "\n",
    "<center> Decision boundary learned by stump: </center>\n",
    "<center><img src = \"Images/dectree_stump_boundary.png\" width = 250/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instead of:\n",
    "    \n",
    "$$ F_{m+1}(x_i) = F_m(x_i) + h_m(x_i) $$\n",
    "\n",
    "with $ h_m(x_i)$ learned by tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Weight learning from mth mistake weakly:\n",
    "\n",
    "$$ F_{m+1}(x_i) = F_m(x_i) + \\alpha h_m(x_i) $$\n",
    "\n",
    "where $\\alpha$ is small. \n",
    "\n",
    "- Weakens effect of learning from error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The learning rate $\\alpha$ controls how much we weight learners:\n",
    "\n",
    "- We weight how we factor in our learning from mistakes of a given step weakly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The learning rate (one factor controlling weakness of learners): connects to gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ F_{m+1}(x_i) = F_m(x_i) + \\alpha h_m(x_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ F_{m+1}(x_i) = F_m(x_i) + \\alpha \\Big(y_i - F_m(x_i)\\Big)_{estimated} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But we know that:\n",
    "$$ - \\nabla_F L|_{x_i} = \\sum_i^{N} \\Big(y_i - F_m(x_i)\\Big) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ F_{m+1}(x_i) = F_m(x_i) + \\alpha \\Big(y_i - F_m(x_i)\\Big)_{estimated} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ F_{m+1}(x_i) = F_m(x_i) - \\alpha \\nabla_F L|_{x_i} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ F_{m+1}(x_i) = F_m(x_i) - \\alpha \\nabla_F L|_{x_i} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Doing gradient descent:\n",
    "- iteratively adding onto (or boosting) estimator to lower loss.\n",
    "- Parameter $\\alpha$ controlling gradient step also representing weakness of learning at each stage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That's why its called gradient boosting!\n",
    "\n",
    "General framework: with different $L$ applies to classification, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A summary of the learning process in more detail:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/update_detailed_process.png\" width = 1000/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Fit a noisy sinusoid with boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.linspace(0,40,1000)\n",
    "y = np.sin(X) + norm.rvs(loc = 0, scale = .4, size = 1000)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Starting point: the dummy model\n",
    "\n",
    "Dummy regressor: average of our $\\{y_i\\}$ as a model of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture dummyapprox\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X, y, label = 'Data')\n",
    "f0 = y.mean()\n",
    "ax.hlines(f0, 0, 40, linestyle = '--', color = 'r', label = 'Dummy Regressor')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xlabel('X')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dummyapprox()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Now walk through process of \"boosting\" this prediction with weak learner sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def simple_boosting_algorithm(X, y, n_learners, learner,\n",
    "                              learning_rate):\n",
    "    y = y.ravel()\n",
    "    # calculates the dummy model\n",
    "    f0 = y.mean()\n",
    "    \n",
    "    # calculates error of first step\n",
    "    residuals = y - f0\n",
    "    \n",
    "    # This next line fills an array of len(y) with the mean of y.\n",
    "    f = np.full(len(y), fill_value=f0)\n",
    "\n",
    "    # start sequential training \n",
    "\n",
    "    for i in range(n_learners):\n",
    "        # error of previous model\n",
    "        residuals = y - f\n",
    "        \n",
    "        # fit error with decision tree\n",
    "        mod = learner.fit(X.reshape(-1, 1), residuals)\n",
    "\n",
    "        # update f\n",
    "        f = learning_rate * mod.predict(X.reshape(-1, 1)) + f\n",
    "        fit_df = pd.DataFrame({'x': X, 'F': f})\n",
    "    return fit_df\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from bokeh.layouts import column,row\n",
    "from bokeh.models import ColumnDataSource, Slider, TextInput, Select\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.themes import Theme\n",
    "import yaml\n",
    "import numpy as np\n",
    "output_notebook()\n",
    "\n",
    "def bk_app(doc):\n",
    "    \n",
    "    func_approx =simple_boosting_algorithm(X=X,\n",
    "                      y=y,\n",
    "                      n_learners= 1,\n",
    "                      learner=DecisionTreeRegressor(max_depth= 1),\n",
    "                      learning_rate=0.02)\n",
    "\n",
    "    source = ColumnDataSource(func_approx)\n",
    "\n",
    "    # Create plots and widgets\n",
    "    plot = figure()\n",
    "\n",
    "    plot.circle(X, y, size = 6, color = 'blue', legend_label= 'Data')\n",
    "    plot.line('x', 'F', source = source, line_width=3, line_alpha=1, color = 'red', legend_label = 'Boosting') \n",
    "\n",
    "    # Create Slider object\n",
    "     \n",
    "    tree_depth = Slider(start=1, end=10, value=1,\n",
    "                    step=1, title='Tree Depth')  \n",
    "    \n",
    "    n_est = TextInput(title=\"Number of estimators\", value = '1')\n",
    "    \n",
    "    lr = Select(title=\"Learning rate\", value='5e-1',\n",
    "               options=['1e-4', '1e-3', '5e-3', '1e-2', '5e-2', '1e-1', '5e-1', '1'])\n",
    "\n",
    "    # Adding callback code\n",
    "    def callback(attr, old, new):\n",
    "        N = n_est.value\n",
    "        depth = tree_depth.value\n",
    "        learn_rate = float(lr.value)\n",
    "        \n",
    "        func_approx =simple_boosting_algorithm(X=X,\n",
    "                              y=y,\n",
    "                              n_learners= int(N),\n",
    "                              learner=DecisionTreeRegressor(max_depth= depth),\n",
    "                              learning_rate= float(learn_rate))\n",
    "\n",
    "        source.data = func_approx\n",
    "\n",
    "\n",
    "    tree_depth.on_change('value', callback)\n",
    "    n_est.on_change('value', callback)\n",
    "    lr.on_change('value', callback)\n",
    "\n",
    "    doc.add_root(row(\n",
    "        plot,\n",
    "        column(tree_depth, n_est, lr),\n",
    "    ))\n",
    "\n",
    "    doc.theme = Theme(json=yaml.load(\"\"\"\n",
    "        attrs:\n",
    "            Figure:\n",
    "                background_fill_color: white\n",
    "                outline_line_color: white\n",
    "                toolbar_location: above\n",
    "                height: 450\n",
    "                width: 450\n",
    "    \"\"\", Loader=yaml.FullLoader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The effects of sequential boosting with weak learners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "show(bk_app, notebook_url=\"http://localhost:8888\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gradient boosting:\n",
    "    \n",
    "- Tuning hyperparameters can be very important for performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Number of estimators (convergence/overfitting)\n",
    "- learning rate (too high...overfit)\n",
    "- tree depth (too large...overfit)\n",
    "\n",
    "Critical hyperparameters in balance between underfitting/overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Playing around with hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "show(bk_app, notebook_url=\"http://localhost:8888\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why do all this?\n",
    "\n",
    "- Decision trees can be very fast.\n",
    "- Weak learners (particularly stumps) are even **faster**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In principal:\n",
    "- can tune and fit models really quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our naive implementation: \n",
    "- can be a little sensitive to overfitting \n",
    "- certainly overfits more than random forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Gets much better with extra randomization: \n",
    "- Random feature subset selection on individual trees \n",
    "- Randomly sampling subset of training data to improve on error at each stage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Even better with regularization on trees:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ L = \\sum_{i=1}^N l(y_i, \\hat{y}_i) + \\gamma \\sum_{m=1}^M \\Omega(h_m)$$\n",
    "- $\\Omega$: complexity of tree at the mth step. \n",
    "- $\\gamma$: controls penalty on complexity \n",
    "\n",
    "**Penalizing building more complex trees but also allows for it if necessary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\gamma$ controls tree pruning. If branch doesn't minimize error (maximize imformation gain) **enough** then cut it.\n",
    "\n",
    "<img src = \"Images/pruning_reg.webp\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Use above strategies + a lot of algorithm optimization\n",
    "\n",
    "- XGBoost (Extreme Gradient Boosting)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/xgboost.png\" />\n",
    "<center>Package integrates well with scikit-learn</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Load in the XGB classifier/regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Hyperparameters to tune and ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| Hyperparameter | Description  | Typical ranges | <center> Comments </center> |\n",
    "| --- | --- | --- | --- |\n",
    "| n_estimator | Number of trees <br> (iterations in sequence) | 50-500 | <center> Can get into low thousands. <br> Increasing beyond certain point: <br> overfitting or no benefit. </center>  |\n",
    "| max_depth | Maximum tree depth of learners | 3-6 |<center> Increment by 1. <br> Changing depth: huge effect. </center>| \n",
    "| learning_rate | The learning rate | 1e-3 to 1 | <center> Proper regularization/randomization <br> allows for faster learning rates <br> ~ 0.1-1 </center>   |\n",
    "|  <font color='red'>gamma </font>| Tree complexity regularization | 0 - 100 | <center> Primary knob for tree regularization </center>   |\n",
    "| <font color='red'>colsample_bytree </font> | <center> Fraction of features <br> randomly sampled by tree </center> | 0.5 - 1 | <center> Regularizing effect  <br>colsample_bylevel, colsample_bynode:<br> add extra degrees of randomization </center>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "XGB estimators fits neatly and seamlessly into scikit-learn model pipelines, grid search, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "params = {'max_depth': [3,4, 5], 'learning_rate': [.1, .3, .5],\n",
    "          'gamma': [0,5,10], 'n_estimators': [50,100, 150] }\n",
    "cv = GridSearchCV(estimator = XGBRegressor(objective='reg:squarederror'), scoring='neg_mean_absolute_error',\n",
    "                  param_grid = params, cv = 5)\n",
    "cv.fit(X_train.reshape(-1,1), y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "best_mod = cv.best_estimator_\n",
    "best_mod.fit(X_train.reshape(-1,1), y_train);\n",
    "y_pred = best_mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "total_preds = best_mod.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_test, y_test, c ='g', label = 'Test data')\n",
    "ax.scatter(X_test, y_pred, c ='r', label = 'Prediction')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Clearly doing pretty well with variance\n",
    "- CV average MAE at scale of intrinsic noise in model.\n",
    "- Also doing decently with bias. Sine wave amplitude ~ 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### How about something a little more complicated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "file_path = \"Data/WHO_life.csv\"\n",
    "who_df = pd.read_csv(file_path).drop(columns = ['Adult Mortality', 'infant deaths',\n",
    "                                            'Year', 'Status', ' thinness 5-9 years', 'Country', \n",
    "                                            'under-five deaths ']).dropna()\n",
    "# clean column names\n",
    "who_df.columns = who_df.columns.str.strip()\n",
    "\n",
    "X_who, y_who = who_df.drop(columns = ['Life expectancy']), who_df['Life expectancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_style": "center",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>percentage expenditure</th>\n",
       "      <th>Hepatitis B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Total expenditure</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Population</th>\n",
       "      <th>thinness  1-19 years</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Schooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>71.279624</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1154</td>\n",
       "      <td>19.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>584.259210</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0.479</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>73.523582</td>\n",
       "      <td>62.0</td>\n",
       "      <td>492</td>\n",
       "      <td>18.6</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>612.696514</td>\n",
       "      <td>327582.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.476</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>73.219243</td>\n",
       "      <td>64.0</td>\n",
       "      <td>430</td>\n",
       "      <td>18.1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>631.744976</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.470</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>78.184215</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2787</td>\n",
       "      <td>17.6</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.52</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>669.959000</td>\n",
       "      <td>3696958.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>0.463</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7.097109</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3013</td>\n",
       "      <td>17.2</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.87</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>63.537231</td>\n",
       "      <td>2978599.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.454</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  percentage expenditure  Hepatitis B  Measles   BMI  Polio  \\\n",
       "0     0.01               71.279624         65.0     1154  19.1    6.0   \n",
       "1     0.01               73.523582         62.0      492  18.6   58.0   \n",
       "2     0.01               73.219243         64.0      430  18.1   62.0   \n",
       "3     0.01               78.184215         67.0     2787  17.6   67.0   \n",
       "4     0.01                7.097109         68.0     3013  17.2   68.0   \n",
       "\n",
       "   Total expenditure  Diphtheria  HIV/AIDS         GDP  Population  \\\n",
       "0               8.16        65.0       0.1  584.259210  33736494.0   \n",
       "1               8.18        62.0       0.1  612.696514    327582.0   \n",
       "2               8.13        64.0       0.1  631.744976  31731688.0   \n",
       "3               8.52        67.0       0.1  669.959000   3696958.0   \n",
       "4               7.87        68.0       0.1   63.537231   2978599.0   \n",
       "\n",
       "   thinness  1-19 years  Income composition of resources  Schooling  \n",
       "0                  17.2                            0.479       10.1  \n",
       "1                  17.5                            0.476       10.0  \n",
       "2                  17.7                            0.470        9.9  \n",
       "3                  17.9                            0.463        9.8  \n",
       "4                  18.2                            0.454        9.5  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_who.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    65.0\n",
       "1    59.9\n",
       "2    59.9\n",
       "3    59.5\n",
       "4    59.2\n",
       "Name: Life expectancy, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_who.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_who_train, X_who_test, y_who_train, y_who_test = train_test_split(X_who, y_who, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "params = {'max_depth': [3,4, 5], 'learning_rate': [.1, .3, .5],\n",
    "          'gamma': [0,5,10], 'colsample_bynode': [.5, .75, 1], 'n_estimators': [50,100, 150] }\n",
    "cv = GridSearchCV(estimator = XGBRegressor(objective='reg:squarederror'), scoring='neg_mean_absolute_error',\n",
    "                  param_grid = params, cv = 5)\n",
    "cv.fit(X_who_train, y_who_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.8035804338331345"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=150, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_regressor = cv.best_estimator_\n",
    "best_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "best_regressor.fit(X_who_train, y_who_train)\n",
    "y_pred_train = best_regressor.predict(\n",
    "    X_who_train)\n",
    "y_pred_test = best_regressor.predict(X_who_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4472050306532118\n"
     ]
    }
   ],
   "source": [
    "MAE = mean_absolute_error(y_who_test, \n",
    "                          y_pred_test)\n",
    "print(MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9828178576652533\n"
     ]
    }
   ],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_who_test,\n",
    "                                  y_pred_test))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Train and test: $R^2$ score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9905380632594476"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_who_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9462697315111486"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_who_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Comparing this to our simple multiple linear regression:\n",
    "- $R^2 = 0.76$ \n",
    "- MAE of ~3.5.\n",
    "- Had to carefully remove correlated features.\n",
    "- Standardize for feature weight importance or regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_style": "center",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp = pd.Series(best_regressor.feature_importances_,\n",
    "             index = X_who.columns).sort_values(ascending = False)\n",
    "fig, ax = plt.subplots()\n",
    "feat_imp.plot(kind = 'barh', ax = ax)\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_title('XGB Regressor: Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Exact same with classification:\n",
    "- XGBClassifier()\n",
    "- basically same hyperparameters\n",
    "- just different objective function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Gradient boosting\n",
    "\n",
    "- Needs tuning\n",
    "- But extremely fast and effective (as has been seen)\n",
    "- Along with random forest: workhorse of classification/regression in many professional workflows."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
